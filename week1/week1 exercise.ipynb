{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "683abaa4-9bd1-4ecf-b323-83ad6bcf31a9",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2955bd7e-b235-4797-abc6-94fd14ab82e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from IPython.display import display, Markdown, update_display\n",
    "import requests\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f68567f-06cc-4535-a045-bd9e9489b231",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12d0b2a6-7a75-4735-a407-d0ca65c0d2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5023fc6-7b08-4320-a617-5fee42706219",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The code snippet you provided uses a Python generator expression combined with a set comprehension. Let's break down its components to understand what it does and why:\n",
       "\n",
       "### Breakdown of the Code\n",
       "\n",
       "1. **Set Comprehension**: \n",
       "   ```python\n",
       "   {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "   ```\n",
       "   - This part creates a set of unique authors from a collection of `books`.\n",
       "   - `books` is expected to be an iterable (like a list) containing dictionaries.\n",
       "   - For each `book` in `books`, it attempts to retrieve the value associated with the key `\"author\"` using `book.get(\"author\")`.\n",
       "   - The `if book.get(\"author\")` condition filters out any `None` or falsy values, meaning only books that have an author will be included in the set.\n",
       "\n",
       "2. **`yield from`**: \n",
       "   ```python\n",
       "   yield from ...\n",
       "   ```\n",
       "   - The `yield from` statement is used in generator functions. It allows you to yield all values from an iterable (in this case, the set of authors) one by one.\n",
       "   - This means when the surrounding function is called, it will produce each author in the set as an output, effectively creating a generator of authors.\n",
       "\n",
       "### What the Code Does\n",
       "\n",
       "- The entire expression:\n",
       "  ```python\n",
       "  yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "  ```\n",
       "  creates a generator that yields the unique authors from the provided list of books. If a book does not have an author (i.e., `book.get(\"author\")` returns `None` or is falsy), it is ignored. The use of a set ensures that each author is yielded only once, even if multiple books share the same author.\n",
       "\n",
       "### Why This Code Might Be Used\n",
       "\n",
       "- **Efficiency**: By using a set, it automatically handles duplicates, meaning if multiple books have the same author, that author will only appear once in the output.\n",
       "- **Generator**: Using `yield from` allows for efficient iteration over potentially large datasets without loading everything into memory at once, as it yields results one at a time.\n",
       "- **Filtering**: It effectively filters out books that lack authors, ensuring the output only includes valid author names.\n",
       "\n",
       "### Use Case\n",
       "\n",
       "This kind of code might be used in applications where you want to process or list all unique authors of a series of books, particularly in scenarios involving large datasets, such as in libraries, databases, or literary analysis tools."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stream = openai.chat.completions.create(\n",
    "    model=MODEL_GPT,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ],\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "response = ''\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "\n",
    "for chunk in stream:\n",
    "    response += chunk.choices[0].delta.content or ''\n",
    "\n",
    "    update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d526400-50e1-4a9e-bbc4-a477b6e3858a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'llama3.2',\n",
       " 'created_at': '2025-01-10T14:59:01.3728421Z',\n",
       " 'message': {'role': 'assistant',\n",
       "  'content': 'This line of code is a part of a generator expression or a generator function, which is used to generate a sequence of values on-the-fly.\\n\\nLet\\'s break it down:\\n\\n- `yield from`: This keyword is used to delegate the execution of the enclosing generator to the generator(s) it calls. It allows you to \"yield\" values from another generator.\\n\\n- `{book.get(\"author\") for book in books if book.get(\"author\")}`: This is a dictionary comprehension, but since `.get()` might return `None`, we can\\'t directly iterate over it. That\\'s why we use the `if` condition.\\n\\nHere\\'s what happens when you run this code:\\n\\n1. The generator function (or expression) starts.\\n2. It checks each book in the list of books to see if it has an \"author\" key and its value is not `None`.\\n3. If a book passes these conditions, it calls `.get(\"author\")` on that book\\'s dictionary and yields this value.\\n4. The process repeats until all books have been checked.\\n\\nThe result of this expression is a generator that produces the author names of all books in the list, one at a time, when you iterate over or use `list()` on it.\\n\\nHere\\'s an example to illustrate how this works:\\n\\n```python\\nbooks = [\\n    {\"title\": \"Book1\", \"author\": \"AuthorA\"},\\n    {\"title\": \"Book2\", \"author\": None},\\n    {\"title\": \"Book3\", \"author\": \"AuthorC\"}\\n]\\n\\nfor author in yield from {book.get(\"author\") for book in books if book.get(\"author\")}:\\n    print(author)\\n```\\n\\nThis will output:\\n\\n```\\nAuthorA\\nAuthorC\\n```'},\n",
       " 'done_reason': 'stop',\n",
       " 'done': True,\n",
       " 'total_duration': 4146055400,\n",
       " 'load_duration': 16013300,\n",
       " 'prompt_eval_count': 52,\n",
       " 'prompt_eval_duration': 35000000,\n",
       " 'eval_count': 355,\n",
       " 'eval_duration': 4083000000}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.post(OLLAMA_API, \n",
    "                         json={\"model\": MODEL_LLAMA, \n",
    "                               \"messages\": [{\n",
    "                                   \"role\": \"user\",\n",
    "                                   \"content\": question\n",
    "                               }], \n",
    "                               \"stream\": False},\n",
    "                        headers={\"Content-Type\": \"application/json\"})\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bdc59680-fb38-4a67-8f3b-1532b41d69ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This line of code is a part of a generator expression or a generator function, which is used to generate a sequence of values on-the-fly.\n",
      "\n",
      "Let's break it down:\n",
      "\n",
      "- `yield from`: This keyword is used to delegate the execution of the enclosing generator to the generator(s) it calls. It allows you to \"yield\" values from another generator.\n",
      "\n",
      "- `{book.get(\"author\") for book in books if book.get(\"author\")}`: This is a dictionary comprehension, but since `.get()` might return `None`, we can't directly iterate over it. That's why we use the `if` condition.\n",
      "\n",
      "Here's what happens when you run this code:\n",
      "\n",
      "1. The generator function (or expression) starts.\n",
      "2. It checks each book in the list of books to see if it has an \"author\" key and its value is not `None`.\n",
      "3. If a book passes these conditions, it calls `.get(\"author\")` on that book's dictionary and yields this value.\n",
      "4. The process repeats until all books have been checked.\n",
      "\n",
      "The result of this expression is a generator that produces the author names of all books in the list, one at a time, when you iterate over or use `list()` on it.\n",
      "\n",
      "Here's an example to illustrate how this works:\n",
      "\n",
      "```python\n",
      "books = [\n",
      "    {\"title\": \"Book1\", \"author\": \"AuthorA\"},\n",
      "    {\"title\": \"Book2\", \"author\": None},\n",
      "    {\"title\": \"Book3\", \"author\": \"AuthorC\"}\n",
      "]\n",
      "\n",
      "for author in yield from {book.get(\"author\") for book in books if book.get(\"author\")}:\n",
      "    print(author)\n",
      "```\n",
      "\n",
      "This will output:\n",
      "\n",
      "```\n",
      "AuthorA\n",
      "AuthorC\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d912448-dbeb-4f56-970c-e5ac62d6c883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6abc347-6dc5-493d-8b99-b5e413cc5421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e22c2aaa-326d-4a16-bed3-a8ed265b7db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling dde5aa3fc5ff... 100% ▕████████████████▏ 2.0 GB                         \n",
      "pulling 966de95ca8a6... 100% ▕████████████████▏ 1.4 KB                         \n",
      "pulling fcc5a6bec9da... 100% ▕████████████████▏ 7.7 KB                         \n",
      "pulling a70ff7e570d9... 100% ▕████████████████▏ 6.0 KB                         \n",
      "pulling 56bb8bd477a5... 100% ▕████████████████▏   96 B                         \n",
      "pulling 34bb5ab01051... 100% ▕████████████████▏  561 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfa547b5-ea09-41d2-9f2b-14cb3f4d419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3431b1ba-4d64-4b3f-b808-91d18930eccf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Generation**: Generative AI can create high-quality content such as articles, blog posts, social media posts, and product descriptions, saving time and effort for content creators.\n",
      "2. **Image and Video Creation**: Generative AI can generate images and videos that match specific styles, moods, or themes, enabling businesses to create visually appealing content without the need for extensive photography or video production expertise.\n",
      "3. **Product Design**: Generative AI can assist in product design by generating 3D models, prototypes, and even functional products, reducing the time and cost associated with traditional design processes.\n",
      "4. **Marketing and Advertising**: Generative AI can create personalized marketing materials such as emails, ads, and social media campaigns, allowing businesses to tailor their messaging to specific customer segments.\n",
      "5. **Sales and Customer Service**: Generative AI-powered chatbots can engage customers, provide support, and even close deals, improving the overall sales experience.\n",
      "6. **Data Analysis and Visualization**: Generative AI can analyze large datasets and generate visualizations that help businesses make data-driven decisions and identify trends and patterns.\n",
      "7. **Supply Chain Optimization**: Generative AI can optimize supply chain operations by predicting demand, identifying bottlenecks, and suggesting alternative routes or suppliers.\n",
      "8. **Financial Modeling**: Generative AI can create complex financial models, forecast revenue streams, and provide scenario-based analysis, helping businesses make more informed investment decisions.\n",
      "9. **Human Resources**: Generative AI can assist with tasks such as talent acquisition, onboarding, and performance evaluation, freeing up HR teams to focus on strategic initiatives.\n",
      "10. **Customer Experience**: Generative AI can create personalized customer experiences by generating customized recommendations, offers, and interactions, enhancing overall customer satisfaction.\n",
      "\n",
      "Some notable businesses that have already leveraged Generative AI include:\n",
      "\n",
      "* **Microsoft**: Uses generative AI to power its Azure Machine Learning platform, which enables developers to build AI models more easily.\n",
      "* **Google**: Utilizes generative AI in its Google Cloud Platform, providing tools for image and video generation, natural language processing, and predictive analytics.\n",
      "* **Amazon**: Employs generative AI in its Alexa virtual assistant, enabling it to generate responses to user queries and provide personalized recommendations.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative uses cases emerge across various industries.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9989b0b-69af-4bc4-8a4f-05fdb559641b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This line of Python code is using a feature called \"yield from\" to extract data from an iterable. Here's a breakdown:\n",
      "\n",
      "1. `for book in books`: This part iterates over the `books` iterable, which contains dictionaries.\n",
      "\n",
      "2. `{book.get(\"author\") for book in books if book.get(\"author\")}`: This is a generator expression. It does two things:\n",
      "   - `if book.get(\"author\")`: Only includes items from the iteration where the \"author\" key exists in each dictionary.\n",
      "   - `for book in books`: Iterates over the same dictionaries as before, but only if they have an \"author\" key.\n",
      "   \n",
      "3. `yield from ...`: This is a special keyword that allows you to delegate to another iterable (like generator expressions) and still control the flow of your function.\n",
      "\n",
      "So when put together, this line of code:\n",
      "\n",
      "- Only iterates over books that have an \"author\"\n",
      "- For each book, it extracts the author's name\n",
      "\n",
      "However, with the use of `yield from`, it actually generates values on-the-fly for the entire iterable, so you don't need to store them in memory. This can be especially useful when dealing with large amounts of data.\n",
      "\n",
      "Here is a more readable version of this line:\n",
      "\n",
      "```python\n",
      "for book in [book for book in books if book.get(\"author\")]:\n",
      "    yield from {book.get(\"author\")}\n",
      "```\n",
      "\n",
      "However, the original line does exactly the same thing but is more concise.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL_LLAMA, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a8667f-fd89-4d5e-ba27-a6c7ded2cced",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
