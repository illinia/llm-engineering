import os
import requests
from bs4 import BeautifulSoup
from IPython.display import Markdown, display


# A class to represent a Webpage
# If you're not familiar with Classes, check out the "Intermediate Python" notebook

# Some websites need you to use proper headers when fetching them:
headers = {
 "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36"
}

class Website:

    def __init__(self, url):
        """
        Create this Website object from the given url using the BeautifulSoup library
        """
        self.url = url
        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.content, 'html.parser')
        self.title = soup.title.string if soup.title else "No title found"
        for irrelevant in soup.body(["script", "style", "img", "input"]):
            irrelevant.decompose()
        self.text = soup.body.get_text(separator="\n", strip=True)


# Let's try one out. Change the website and add print statements to follow along.

ed = Website("https://edwarddonner.com")
print(ed.title)
print(ed.text)


# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish."

system_prompt = "당신은 웹사이트의 내용을 분석하고 \
짧은 요약을 제공하는 조수이며, 탐색과 관련된 텍스트는 무시합니다. \
마크다운으로 응답합니다."


# A function that writes a User Prompt that asks for summaries of websites:

def user_prompt_for(website):
    user_prompt = f"당신은 제목의 웹사이트를 보고 있습니다 {website.title}"
    user_prompt += "\n이 웹사이트의 내용은 다음과 같습니다. \
    이 웹사이트의 간략한 요약을 마크다운으로 제공하세요. \
    뉴스나 공지 사항이 포함되어 있는 경우, 이것도 요약하세요.\n\n"
    user_prompt += website.text
    return user_prompt


print(user_prompt_for(ed))


# See how this function creates exactly the format above

def messages_for(website):
    return [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt_for(website)}
    ]


# Try this out, and then try for a few more websites

messages_for(ed)


# And now: call the OpenAI API. You will get very familiar with this!

# def summarize(url):
#     website = Website(url)
#     response = openai.chat.completions.create(
#         model = "gpt-4o-mini",
#         messages = messages_for(website)
#     )
#     return response.choices[0].message.content


# Constants

OLLAMA_API = "http://localhost:11434/api/chat"
HEADERS = {"Content-Type": "application/json"}
MODEL = "llama3.2"





payload = {
        "model": MODEL,
        "messages": messages_for(ed),
        "stream": False
    }


# Let's just make sure the model is loaded

!ollama pull llama3.2


import ollama

response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)
print(response.json()['message']['content'])


import ollama

response = ollama.chat(model=MODEL, messages=messages)
print(response['message']['content'])



